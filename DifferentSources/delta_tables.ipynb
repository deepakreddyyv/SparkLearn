{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7265ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d21fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/04 21:49:33 WARN Utils: Your hostname, deepak-ubuntu, resolves to a loopback address: 127.0.1.1; using 192.168.31.105 instead (on interface wlp1s0)\n",
      "25/10/04 21:49:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/deepak/anaconda3/envs/ai_data/lib/python3.13/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /home/deepak/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /home/deepak/.ivy2.5.2/jars\n",
      "io.delta#delta-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1d3cc87f-b67c-4065-8cab-29a199cbe623;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.13;4.0.0 in central\n",
      "\tfound io.delta#delta-storage;4.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.13.1 in central\n",
      ":: resolution report :: resolve 402ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.13;4.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;4.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.13.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1d3cc87f-b67c-4065-8cab-29a199cbe623\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/6ms)\n",
      "25/10/04 21:49:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/04 21:49:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f7bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/04 21:49:53 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/10/04 21:49:58 WARN OptimisticTransaction: Change in the table id detected in txn. Table id for txn on table at file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people was 6dd47f0e-29f9-429f-abc1-1c80be839d79 when the txn was created and is now changed to 5e1f28cc-b03e-4f80-95e1-7c42245aeead.\n",
      "25/10/04 21:49:59 WARN DeltaLog: Change in the table id detected while updating snapshot. \n",
      "Previous snapshot = Snapshot(path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log, version=1, metadata=Metadata(6dd47f0e-29f9-429f-abc1-1c80be839d79,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"age\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1759569378968)), logSegment=LogSegment(file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log,1,ArraySeq(DeprecatedRawLocalFileStatus{path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1759569383048; access_time=1759569385108; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}, DeprecatedRawLocalFileStatus{path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log/00000000000000000001.json; isDirectory=false; length=1087; replication=1; blocksize=33554432; modification_time=1759569799262; access_time=1759569799515; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}),org.apache.spark.sql.delta.EmptyCheckpointProvider$@53d854a3,1759569799262), checksumOpt=Some(VersionChecksum(Some(687bbbac-cca3-4a55-857a-d4e6da347fdc),4863,5,None,None,1,1,None,Some(List()),Some(List()),Metadata(6dd47f0e-29f9-429f-abc1-1c80be839d79,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"age\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1759569378968)),Protocol(1,2),None,None,Some(List(AddFile(part-00000-96a9222c-5e21-4359-9aba-df0994999fcf-c000.snappy.parquet,Map(),967,1759569382604,false,{\"numRecords\":1,\"minValues\":{\"id\":1,\"name\":\"Alice\",\"age\":10},\"maxValues\":{\"id\":1,\"name\":\"Alice\",\"age\":10},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None), AddFile(part-00001-1cb809b0-919c-40f6-90fb-401c6a4c2b02-c000.snappy.parquet,Map(),953,1759569382626,false,{\"numRecords\":1,\"minValues\":{\"id\":2,\"name\":\"Bob\",\"age\":20},\"maxValues\":{\"id\":2,\"name\":\"Bob\",\"age\":20},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None), AddFile(part-00002-9efae35c-cab6-46ae-9d9b-5789a23fbc7b-c000.snappy.parquet,Map(),981,1759569382604,false,{\"numRecords\":1,\"minValues\":{\"id\":3,\"name\":\"Charlie\",\"age\":30},\"maxValues\":{\"id\":3,\"name\":\"Charlie\",\"age\":30},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None), AddFile(part-00000-4a954719-62b9-4cfa-adc9-1254e1238b63-c000.snappy.parquet,Map(),974,1759569799242,false,{\"numRecords\":1,\"minValues\":{\"id\":4,\"name\":\"Deepak\",\"age\":24},\"maxValues\":{\"id\":4,\"name\":\"Deepak\",\"age\":24},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None), AddFile(part-00001-d9751fbd-e45e-451e-a88c-ef10b73f460b-c000.snappy.parquet,Map(),988,1759569799242,false,{\"numRecords\":1,\"minValues\":{\"id\":5,\"name\":\"Srikanth\",\"age\":27},\"maxValues\":{\"id\":5,\"name\":\"Srikanth\",\"age\":27},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None))))))\n",
      "New snapshot = Snapshot(path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log, version=2, metadata=Metadata(5e1f28cc-b03e-4f80-95e1-7c42245aeead,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"age\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1759594791061)), logSegment=LogSegment(file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log,2,ArraySeq(DeprecatedRawLocalFileStatus{path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log/00000000000000000000.json; isDirectory=false; length=1995; replication=1; blocksize=33554432; modification_time=1759569383048; access_time=1759569385108; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}, DeprecatedRawLocalFileStatus{path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log/00000000000000000001.json; isDirectory=false; length=1087; replication=1; blocksize=33554432; modification_time=1759569799262; access_time=1759569799515; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}, DeprecatedRawLocalFileStatus{path=file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people/_delta_log/00000000000000000002.json; isDirectory=false; length=3023; replication=1; blocksize=33554432; modification_time=1759594798466; access_time=1759594798425; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}),org.apache.spark.sql.delta.EmptyCheckpointProvider$@53d854a3,1759594798466), checksumOpt=Some(VersionChecksum(Some(c8df7e8a-6bbc-4f3b-965c-570a865af582),2901,3,None,None,1,1,None,Some(List()),Some(List()),Metadata(5e1f28cc-b03e-4f80-95e1-7c42245aeead,null,null,Format(parquet,Map()),{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"age\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]},List(),Map(),Some(1759594791061)),Protocol(1,2),None,None,Some(List(AddFile(part-00002-d54f0a45-7c17-449b-b0d1-e99df414e8f4-c000.snappy.parquet,Map(),981,1759594792947,false,{\"numRecords\":1,\"minValues\":{\"id\":3,\"name\":\"Charlie\",\"age\":30},\"maxValues\":{\"id\":3,\"name\":\"Charlie\",\"age\":30},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None), AddFile(part-00000-46fd1429-a52e-4709-b8cb-8836c9e16725-c000.snappy.parquet,Map(),967,1759594792946,false,{\"numRecords\":1,\"minValues\":{\"id\":1,\"name\":\"Alice\",\"age\":10},\"maxValues\":{\"id\":1,\"name\":\"Alice\",\"age\":10},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None), AddFile(part-00001-3fe4ec8d-5995-4067-9681-f4aca2b69250-c000.snappy.parquet,Map(),953,1759594792946,false,{\"numRecords\":1,\"minValues\":{\"id\":2,\"name\":\"Bob\",\"age\":20},\"maxValues\":{\"id\":2,\"name\":\"Bob\",\"age\":20},\"nullCount\":{\"id\":0,\"name\":0,\"age\":0}},null,null,None,None,None)))))).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE people USING DELTA\n",
    "AS SELECT * FROM VALUES\n",
    "  (1, 'Alice', 10),\n",
    "  (2, 'Bob', 20),\n",
    "  (3, 'Charlie', 30)\n",
    "  AS t(id, name, age)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00094614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------------+----------------------------+-----------+------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name                        |description|location                                                                            |createdAt              |lastModified           |partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----------------------------+-----------+------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |5e1f28cc-b03e-4f80-95e1-7c42245aeead|spark_catalog.default.people|NULL       |file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse/people|2025-10-04 21:49:51.061|2025-10-04 21:49:58.466|[]              |[]               |3       |2901       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----------------------------+-----------+------------------------------------------------------------------------------------+-----------------------+-----------------------+----------------+-----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE DETAIL people\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3aa627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "Insert into people\n",
    "          values \n",
    "          (4, 'Deepak', 24),\n",
    "          (5, 'Srikanth', 27)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50368d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation                        |operationParameters                                                                           |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|3      |2025-10-04 21:50:11.559|NULL  |NULL    |WRITE                            |{mode -> Append, partitionBy -> []}                                                           |NULL|NULL    |NULL     |2          |Serializable  |true         |{numFiles -> 2, numOutputRows -> 2, numOutputBytes -> 1962}                                               |NULL        |Apache-Spark/4.0.1 Delta-Lake/4.0.0|\n",
      "|2      |2025-10-04 21:49:58.466|NULL  |NULL    |CREATE OR REPLACE TABLE AS SELECT|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|NULL    |NULL     |1          |Serializable  |false        |{numFiles -> 3, numRemovedFiles -> 5, numRemovedBytes -> 4863, numOutputRows -> 3, numOutputBytes -> 2901}|NULL        |Apache-Spark/4.0.1 Delta-Lake/4.0.0|\n",
      "|1      |2025-10-04 14:53:19.262|NULL  |NULL    |WRITE                            |{mode -> Append, partitionBy -> []}                                                           |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 2, numOutputRows -> 2, numOutputBytes -> 1962}                                               |NULL        |Apache-Spark/4.0.1 Delta-Lake/4.0.0|\n",
      "|0      |2025-10-04 14:46:23.048|NULL  |NULL    |CREATE TABLE AS SELECT           |{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> true, properties -> {}}|NULL|NULL    |NULL     |NULL       |Serializable  |true         |{numFiles -> 3, numOutputRows -> 3, numOutputBytes -> 2901}                                               |NULL        |Apache-Spark/4.0.1 Delta-Lake/4.0.0|\n",
      "+-------+-----------------------+------+--------+---------------------------------+----------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE HISTORY people\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f26a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n",
      "| id|    name|age|\n",
      "+---+--------+---+\n",
      "|  1|   Alice| 10|\n",
      "|  2|     Bob| 20|\n",
      "|  3| Charlie| 30|\n",
      "|  4|  Deepak| 24|\n",
      "|  5|Srikanth| 27|\n",
      "+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from people version as of 1\n",
    "\"\"\").orderBy('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684ca33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show schemas\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a45ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show catalogs\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76d020d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE DATABASE gizmobox;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3aa6c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "drop schema gizmobox;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426ca8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "| gizmobox|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show databases;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f252ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/home/deepak/programs/python/sparkLearn/DifferentSources/spark-warehouse'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.warehouse.dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac95ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
